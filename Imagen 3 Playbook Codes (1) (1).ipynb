{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckAx2rBQFFa9"
   },
   "source": [
    "# **Imagen 3: Hands On Coding Lab Session**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSyT_DAmGYhb"
   },
   "source": [
    "## **Overview**\n",
    "\n",
    "### **Imagen 3: Google's Most Advanced Text-to-Image Model**\n",
    "Imagen 3 is the latest and most capable text-to-image generation model developed by Google DeepMind. It represents a significant leap forward from its predecessor, Imagen 2, focusing on enhanced prompt understanding, photorealism, and particularly, accurate text rendering within images.\n",
    "\n",
    "### **Agenda**\n",
    "\n",
    "In this lab session, you will learn how to use the Vertex AI SDK for Python to interact with the Imagen 3/Imagen 3 Fast models to generate images and use other AI model for image verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibe6-t9fFsxk",
    "tags": []
   },
   "source": [
    "## Section 1: **Setting Up**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2lXxZfnLwca"
   },
   "source": [
    "### **Import libraries**\n",
    "\n",
    "The **Vertex AI SDK** for Python acts as a bridge between your Python codebase and Google Cloud Platform's (GCP) machine learning services. This makes it easy for you to access and utilize powerful Google AI models, like Imagen for generating images or Gemini for advanced language tasks, directly within your notebooks or other Python environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWe64xYju98p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.vision_models import ImageGenerationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yHwaY00y6u7"
   },
   "source": [
    "### **Initialize Vertex AI**\n",
    "\n",
    "You need to initialize the Vertex AI SDK to configure it with your specific project ID, and location, to authenticate and communicate with the correct Google Cloud AI services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qWKEognzy6Im",
    "outputId": "0d7075be-66a0-485b-89ef-53ae95c4583f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"<project-id>\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID)\n",
    "print(\"Vertex AI Initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaxmiCPpzUyI"
   },
   "source": [
    "## **Section 2: Creating Images**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bohNboAATGwi"
   },
   "source": [
    "### **Load AI Models**\n",
    "Here are the current Image Generation AI model you can use:\n",
    "\n",
    "*   Imagen 3 (latest version) : ```imagen-3.0-generate-002 ```\n",
    "*   Imagen 3 :  ```imagen-3.0-generate-001 ```\n",
    "*   Imagen 3 Fast: ```imagen-3.0-fast-generate-001```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOoLHFQbvoEE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagen_id = \"<model-id>\"\n",
    "\n",
    "imagen = ImageGenerationModel.from_pretrained(imagen_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvxKmkcmPZ8p"
   },
   "source": [
    "### **Generate your first image**\n",
    "\n",
    "`generate_images() `function to create images. This function needs two parameters:\n",
    "\n",
    "- `prompt`: Tells AI what image to create\n",
    "- `number_of_images`: How many images to generate (up to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTvb1vkXPagt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = imagen.generate_images(\n",
    "    prompt=\"a pizza on a plate\",\n",
    "    number_of_images=1\n",
    ")\n",
    "\n",
    "images[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYMezQrLC7DA"
   },
   "source": [
    "### **Saving your image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhRFIhh1CM3f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "images[0].save(\"name.filetype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DsptNnLEe_p"
   },
   "source": [
    "### **Exploring Parameters**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You can use extra settings to get images exactly how you want them.\n",
    "**Note: Optional Parameters only work for the `imagen-3.0-generate-001` and `imagen-3.0-fast-generate-001`**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Imagen Model Parameters:**\n",
    "\n",
    "- `negative_prompt` : This tells our AI what not to include in our images. You can list out those things within this the parameter (e.g., \"blurry, text, ugly\").\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- `language`: Offers multilingual support: As of now, supported language are:\n",
    "  - en: English\n",
    "  - hi: Hindi\n",
    "  - ja: Japanese\n",
    "  - ko: Korean\n",
    "  - zh: Chinese(simplified)\n",
    "  - auto: Automatic detection\n",
    "\n",
    "\n",
    "\n",
    "- `aspect_ratio`: Changes the aspect ratio of the generated image. Supported values are:\n",
    "  - 1:1 (default)\n",
    "  - 3:4\n",
    "  - 4:3\n",
    "  - 9:16\n",
    "  - 16:9\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HC5Ab9ZEnq6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "supported_model = \"imagen-3.0-generate-002\"\n",
    "\n",
    "model = ImageGenerationModel.from_pretrained(supported_model)\n",
    "\n",
    "images = model.generate_images(\n",
    "  prompt=\"çƒ¤ç®±é‡Œçš„æŠ«è¨\",\n",
    "  number_of_images=1,\n",
    "  negative_prompt= \"beef, pepperoni\",\n",
    "  language=\"zh\",\n",
    "  aspect_ratio=\"16:9\"\n",
    "    \n",
    ")\n",
    "\n",
    "# Optional. View the generated image in a notebook.\n",
    "images[0].save(\"test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eB9nud_Nk02"
   },
   "source": [
    "## **Section 3: Responsible AI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYbet_oUDSey",
    "tags": []
   },
   "source": [
    "### **SynthID Verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lw7Ajy-MlLwq",
    "outputId": "870311a2-4f49-4206-bd30-d1d6ecd4d485",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import WatermarkVerificationModel\n",
    "\n",
    "verification_model = WatermarkVerificationModel.from_pretrained(\n",
    "    \"imageverification@001\"\n",
    ")\n",
    "\n",
    "watermark_verification_response = verification_model.verify_image(images[0])\n",
    "\n",
    "if (watermark_verification_response.watermark_verification_result == \"ACCEPT\"):\n",
    "    print(\"This picture is AI Generated\")\n",
    "else:\n",
    "    print(\"This picture is real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A8i6m8p1u0A2",
    "outputId": "7784090f-fd39-4354-f764-67f53f67fb77",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.vision_models import Image\n",
    "\n",
    "filepath = \"/home/jupyter/imagentest/dog_image.jpeg\"\n",
    "img = Image.load_from_file(filepath)\n",
    "\n",
    "watermark_verification_response = verification_model.verify_image(img)\n",
    "\n",
    "print(watermark_verification_response.watermark_verification_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3adE3lJDxNd"
   },
   "source": [
    "## **Lab Activity: Emoji Scene Maker**\n",
    "\n",
    "\n",
    "In this fun and creative lab activity, weâ€™ll be building an Emoji Scene Generator! Since Imagen 3 doesnâ€™t quite understand emojis on its own, weâ€™ll get a little help from another awesome Google AI model â€” Gemini â€” to bring our emoji-inspired scenes to life. Letâ€™s explore how we can combine the power of different AI tools to turn simple emojis into vivid image prompts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdIqSZALpsk5"
   },
   "source": [
    "## Step 1: Importing Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rl7h05gpy_O",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click here to show the full code</summary>\n",
    "\n",
    "```\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.vision_models import ImageGenerationModel\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9fglLrdrqIY"
   },
   "source": [
    "## Step 2: Initialize Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFHN41WUrzwz",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click here to show the full code</summary>\n",
    "\n",
    "```\n",
    "\n",
    "PROJECT_ID = \"\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P16JwvVmr0N2"
   },
   "source": [
    "## Step 3: Load Models\n",
    "\n",
    "- Imagen 3 : ```imagen-3.0-generate-002 ```, OR ```imagen-3.0-generate-001 ```, OR ```imagen-3.0-fast-generate-001```\n",
    "- Gemini 2.0: ```gemini-2.0-flash```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVwgLAXtyhZH",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click here to show the full code</summary>\n",
    "\n",
    "```\n",
    "\n",
    "gemini_id = \"gemini-2.0-flash\"\n",
    "imagen_id = \"imagen-3.0-generate-002\"\n",
    "\n",
    "model = ImageGenerationModel.from_pretrained(imagen_id)\n",
    "gemini = GenerativeModel(gemini_id)\n",
    "print(\"âœ… Vertex AI Initialized and models are loaded\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIOwoz91yhxz"
   },
   "source": [
    "## Step 4 : Create Functions for Text and Image Generation\n",
    "\n",
    "Create two functions:\n",
    "- emojis_to_prompt : Analyse emojis then generate prompt using Gemini Model\n",
    "- prompt_to_image : Pass generated prompt from Gemini to Imagen to create our image\n",
    "\n",
    "\n",
    "**Copy paste this prompt to send to Gemini**\n",
    "```\n",
    "        Analyze these emojis: {emojis} .If none is given, choose it yourself.\n",
    "\n",
    "        Create a short (1-2 sentences) and highly visual scene description\n",
    "        based *only* on the concepts represented by these emojis. Combine the concepts in an\n",
    "        unexpected, or absurd way. The description should be suitable as a prompt\n",
    "        for Imagen 3. ONLY show the short sentence(s) as your response without any other texts.\n",
    "\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlj_sK5hysv7",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click here to show the full code</summary>\n",
    "\n",
    "    \n",
    "```\n",
    "def emojis_to_prompt(emojis):\n",
    "    \n",
    "    funny_prompt = None\n",
    "    \n",
    "    prompt_for_gemini = f\"\"\"\n",
    "    Analyze these emojis: {emojis} .If none is given, choose it yourself.\n",
    "\n",
    "        Create a short (1-2 sentences) and highly visual scene description\n",
    "        based *only* on the concepts represented by these emojis. Combine the concepts in an\n",
    "        unexpected, or absurd way. The description should be suitable as a prompt\n",
    "        for Imagen 3. ONLY show the short sentence(s) as your response without any other texts.\n",
    "    \"\"\"\n",
    "    \n",
    "    text_response = gemini.generate_content(prompt_for_gemini)    \n",
    "    funny_prompt = text_response.text.strip()\n",
    "    \n",
    "    print(\"Gemini prompt: \" + funny_prompt)\n",
    "    \n",
    "    prompt_to_image(funny_prompt)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def prompt_to_image(prompt):\n",
    "    \n",
    "    image = imagen.generate_images(\n",
    "        prompt=prompt+\" Style: Digital Painting\",\n",
    "        number_of_images=1,\n",
    "        aspect_ratio=\"4:3\",\n",
    "        negative_prompt=\"ugly\",\n",
    "        guidance_scale=\"0\"\n",
    "    )\n",
    "\n",
    "    image[0].show()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9RmC6U2DKx3U"
   },
   "source": [
    "## Final Step : Insert Your Emojis!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSlAPvHyKxCZ",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here to show the full code</summary>\n",
    "        \n",
    "        \n",
    "```\n",
    "emojis = \"\"\n",
    "\n",
    "emojis_to_prompt(emojis)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ˜€ ğŸ˜ƒ ğŸ˜„ ğŸ˜ ğŸ˜† ğŸ˜… ğŸ¤£ ğŸ˜‚ ğŸ¥² ğŸ˜Š ğŸ˜‡ ğŸ¥° ğŸ˜ ğŸ¤© ğŸ˜˜ ğŸ˜— ğŸ˜™ ğŸ˜š ğŸ™‚ ğŸ«  ğŸ˜‰ ğŸ¤¨ ğŸ§ ğŸ¤“ ğŸ˜ ğŸ¥¸ ğŸ˜” ğŸ¥º ğŸ˜Ÿ ğŸ˜¥ ğŸ˜¢ ğŸ˜­ ğŸ˜¨ ğŸ˜© ğŸ¤¯ ğŸ˜¬ ğŸ˜®â€ğŸ’¨ ğŸ¥¶ ğŸ¥µ ğŸ˜³ ğŸ˜± ğŸ˜– ğŸ˜ ğŸ˜“ ğŸ¤¢ ğŸ¤® ğŸ¤§ ğŸ¤• ğŸ¥´ ğŸ˜µâ€ğŸ’« ğŸ¤¯ ğŸ˜‡ ğŸ¤  ğŸ¤¡ ğŸ‘¹ ğŸ‘º ğŸ‘» ğŸ‘½ ğŸ‘¾ ğŸ¤– ğŸ‘‹ ğŸ–ï¸ âœ‹ ğŸ¤š ğŸ–– ğŸ‘Œ ğŸ¤Œ ğŸ¤ ğŸ¤ ğŸ«¶ ğŸ™ ğŸ‘ ğŸ™Œ ğŸ«¶ ğŸ¤ ğŸ«‚ ğŸ‘¤ ğŸ‘¥ ğŸ‘£ ğŸ¶ ğŸ± ğŸ­ ğŸ¹ ğŸ° ğŸ¦Š ğŸ» ğŸ¼ ğŸ¨ ğŸ¯ ğŸ¦ ğŸ® ğŸ· ğŸ¸ ğŸ’ ğŸ” ğŸ§ ğŸ¦ ğŸ¦‰ ğŸ¦‡ ğŸ¦‹ ğŸ› ğŸœ ğŸ ğŸ ğŸŒ ğŸ¦€ ğŸ ğŸ¦ ğŸ¢ ğŸ  ğŸ¡ ğŸ¬ ğŸ³ ğŸ¦ˆ ğŸ™ ğŸš ğŸª´ ğŸŒ± ğŸŒ¿ â˜˜ï¸ ğŸ€ ğŸ ğŸ‚ ğŸƒ ğŸŒ¸ ğŸŒ· ğŸŒ¹ ğŸŒ» ğŸŒ¼ ğŸŒº ğŸ„ ğŸŒ³ ğŸŒ´ ğŸŒµ ğŸ ğŸ ğŸŒ ğŸ“ ğŸ‡ ğŸ‰ ğŸŠ ğŸ‹ ğŸ¥­ ğŸ ğŸ¥ ğŸ¥‘ ğŸ… ğŸ† ğŸ¥• ğŸŒ½ ğŸŒ¶ï¸ ğŸ¥” ğŸ§… ğŸ§„ ğŸ¥¦ ğŸ¥¬ ğŸ¥’ ğŸ«‘ ğŸ— ğŸ– ğŸ¥“ ğŸ” ğŸŸ ğŸ• ğŸŒ­ ğŸ¥ª ğŸŒ® ğŸŒ¯ ğŸœ ğŸ ğŸ™ ğŸš ğŸ› ğŸ£ ğŸ¤ ğŸ¦ ğŸ§ ğŸ¨ ğŸ© ğŸª ğŸ‚ ğŸ° ğŸ§ ğŸ« ğŸ¬ ğŸ­ ğŸ® ğŸ¯ ğŸ¿ ğŸ§‚ ğŸ§ˆ ğŸ³ ğŸ§‡ ğŸ¥ ğŸ¥¨ ğŸ¥© ğŸ¥ª ğŸ¥£ ğŸ¥— ğŸ¿ ğŸ¥« ğŸ¥Ÿ ğŸ¦ª ğŸ« ğŸº ğŸ» ğŸ¥‚ ğŸ· ğŸ¥ƒ ğŸ¸ ğŸ¹ ğŸ§‰ ğŸ§Š ğŸ¥¤ â˜• ğŸµ ğŸ¶ ğŸ¼ ğŸ¥› ğŸ«– ğŸ«˜ âš½ ğŸ€ ğŸˆ âš¾ ğŸ¥ ğŸ¾ ğŸ ğŸ‰ ğŸ¥ ğŸ³ ğŸ ğŸ‘ ğŸ’ ğŸ¥ ğŸª ğŸ£ ğŸ›¶ ğŸŠ ğŸ„ ğŸš´ ğŸšµ ğŸ¤¸â€â™€ï¸ ğŸ‹ï¸â€â™‚ï¸ ğŸŒï¸â€â™‚ï¸ ğŸ§˜â€â™€ï¸ ğŸ§—â€â™‚ï¸ ğŸ‡ ğŸ‚ â›·ï¸ â›¸ï¸ ğŸ¹ ğŸ¯ ğŸ® ğŸ° ğŸš— ğŸš• ğŸš“ ğŸš‘ ğŸš’ ğŸšŒ ğŸš‚ âœˆï¸ ğŸš€ ğŸš¢ ğŸš¤ â›µ ğŸš² ğŸ›´ ğŸ›µ ğŸ›¸ ğŸ›°ï¸ ğŸš  ğŸš¡ ğŸš¦ ğŸš§ â›½ ğŸ—ºï¸ ğŸ”ï¸ ğŸŒ‹ ğŸœï¸ ğŸï¸ ğŸï¸ ğŸ–ï¸ ğŸ•ï¸ ğŸ›¤ï¸ ğŸŒ… ğŸŒ„ ğŸŒƒ ğŸŒ  ğŸ‡ ğŸ† ğŸŒˆ ğŸŒ‰ ğŸ  ğŸ˜ï¸ ğŸ° ğŸ¢ ğŸ­ ğŸ—¼ ğŸ—½ ğŸ—¿ âŒš ğŸ“± ğŸ’» âŒ¨ï¸ ğŸ–±ï¸ ğŸ–¨ï¸ ğŸ•¹ï¸ ğŸ“¸ ğŸ”¦ ğŸ“º ğŸ“» ğŸ’¾ ğŸ’¿ ğŸ“¼ ğŸ“· ğŸ“¹ ğŸ¥ ğŸ¬ ğŸ¤ ğŸ§ ğŸ¼ ğŸ¹ ğŸ¥ ğŸ· ğŸº ğŸ¸ ğŸ» ğŸª• ğŸµ ğŸ¶ ğŸ™ï¸ ğŸ“» ğŸ“± ğŸ“ ğŸ“Ÿ ğŸ“  ğŸ”‹ ğŸ”Œ ğŸ’¡ ğŸ’¸ ğŸ’µ ğŸ’¶ ğŸ’· ğŸ’´ ğŸ’° ğŸ’³ ğŸ’ âš–ï¸ ğŸ’¼ ğŸ‘œ ğŸ’ ğŸ‘” ğŸ‘• ğŸ‘– ğŸ‘— ğŸ‘˜ ğŸ¥» ğŸ©± ğŸ©³ ğŸ§¥ ğŸ§¤ ğŸ§£ ğŸ§¢ ğŸ‘’ ğŸ“ ğŸ‘‘ ğŸ’ ğŸ‘“ ğŸ¥½ ğŸ’„ ğŸ’‹ ğŸ‘£ ğŸ§µ ğŸ§¶ ğŸª¡ ğŸ§¸ ğŸª ğŸª„ ğŸˆ ğŸ‰ ğŸŠ ğŸ ğŸ ğŸ ğŸª… ğŸª† ğŸ­ ğŸ–¼ï¸ ğŸ§µ ğŸ§¶ ğŸª¡ ğŸ§¸ ğŸª ğŸª„ ğŸˆ ğŸ‰ ğŸŠ ğŸ ğŸ ğŸ ğŸª… ğŸª† âŒš ğŸ“± ğŸ’» âŒ¨ï¸ ğŸ–±ï¸ ğŸ–¨ï¸ ğŸ•¹ï¸ ğŸ“¸ ğŸ”¦ ğŸ“º ğŸ“» ğŸ’¾ ğŸ’¿ ğŸ“¼ ğŸ“· ğŸ“¹ ğŸ¥ ğŸ¬ ğŸ¤ ğŸ§ ğŸ¼ ğŸ¹ ğŸ¥ ğŸ· ğŸº ğŸ¸ ğŸ» ğŸª• ğŸµ ğŸ¶ ğŸ™ï¸ ğŸ“» ğŸ“± ğŸ“ ğŸ“Ÿ ğŸ“  ğŸ”‹ ğŸ”Œ ğŸ’¡ ğŸ’¸ ğŸ’µ ğŸ’¶ ğŸ’· ğŸ’´ ğŸ’° ğŸ’³ ğŸ’ âš–ï¸ ğŸ’¼ ğŸ‘œ ğŸ’ ğŸ‘” ğŸ‘• ğŸ‘– ğŸ‘— ğŸ‘˜ ğŸ¥» ğŸ©± ğŸ©³ ğŸ§¥ ğŸ§¤ ğŸ§£ ğŸ§¢ ğŸ‘’ ğŸ“ ğŸ‘‘ ğŸ’ ğŸ‘“ ğŸ¥½ ğŸ’„ ğŸ’‹ ğŸ‘£ ğŸ§µ ğŸ§¶ ğŸª¡ ğŸ§¸ ğŸª ğŸª„ ğŸˆ ğŸ‰ ğŸŠ ğŸ ğŸ ğŸ ğŸª… ğŸª† ğŸ­ ğŸ–¼ï¸ ğŸ§µ ğŸ§¶ ğŸª¡ ğŸ§¸ ğŸª ğŸª„ ğŸˆ ğŸ‰ ğŸŠ ğŸ ğŸ ğŸ ğŸª… ğŸª† ğŸ­ ğŸ–¼ï¸ ğŸ—ºï¸ ğŸ§­ ğŸ§± ğŸªµ ğŸ· ğŸ ğŸ ğŸŒ ğŸ“ ğŸ‡ ğŸ‰ ğŸŠ ğŸ‹ ğŸ¥­ ğŸ ğŸ¥ ğŸ¥‘ ğŸ… ğŸ† ğŸ¥• ğŸŒ½ ğŸŒ¶ï¸ ğŸ¥” ğŸ§… ğŸ§„ ğŸ¥¦ ğŸ¥¬ ğŸ¥’ ğŸ«‘ ğŸ— ğŸ– ğŸ¥“ ğŸ” ğŸŸ ğŸ• ğŸŒ­ ğŸ¥ª ğŸŒ® ğŸŒ¯ ğŸœ ğŸ ğŸ™ ğŸš ğŸ› ğŸ£ ğŸ¤ ğŸ¦ ğŸ§ ğŸ¨ ğŸ© ğŸª ğŸ‚ ğŸ° ğŸ§ ğŸ« ğŸ¬ ğŸ­ ğŸ® ğŸ¯ ğŸ¿ ğŸ§‚ ğŸ§ˆ ğŸ³ ğŸ§‡ ğŸ¥ ğŸ¥¨ ğŸ¥© ğŸ¥ª ğŸ¥£ ğŸ¥— ğŸ¿ ğŸ¥« ğŸ¥Ÿ ğŸ¦ª ğŸ« ğŸº ğŸ» ğŸ¥‚ ğŸ· ğŸ¥ƒ ğŸ¸ ğŸ¹ ğŸ§‰ ğŸ§Š ğŸ¥¤ â˜• ğŸµ ğŸ¶ ğŸ¼ ğŸ¥› ğŸ«– ğŸ«˜ âš½ ğŸ€ ğŸˆ âš¾ ğŸ¥ ğŸ¾ ğŸ ğŸ‰ ğŸ¥ ğŸ³ ğŸ ğŸ‘ ğŸ’ ğŸ¥ ğŸª ğŸ£ ğŸ›¶ ğŸŠ ğŸ„ ğŸš´ ğŸšµ ğŸ¤¸â€â™€ï¸ ğŸ‹ï¸â€â™‚ï¸ ğŸŒï¸â€â™‚ï¸ ğŸ§˜â€â™€ï¸ ğŸ§—â€â™‚ï¸ ğŸ‡ ğŸ‚ â›·ï¸ â›¸ï¸ ğŸ¹ ğŸ¯ ğŸ® ğŸ° ğŸš— ğŸš• ğŸš“ ğŸš‘ ğŸš’ ğŸšŒ ğŸš‚ âœˆï¸ ğŸš€ ğŸš¢ ğŸš¤ â›µ ğŸš² ğŸ›´ ğŸ›µ ğŸ›¸ ğŸ›°ï¸ ğŸš  ğŸš¡ ğŸš¦ ğŸš§ â›½ ğŸ—ºï¸ ğŸ”ï¸ ğŸŒ‹ ğŸœï¸ ğŸï¸ ğŸï¸ ğŸ–ï¸ ğŸ•ï¸ ğŸ›¤ï¸ ğŸŒ… ğŸŒ„ ğŸŒƒ ğŸŒ  ğŸ‡ ğŸ† ğŸŒˆ ğŸŒ‰ ğŸ  ğŸ˜ï¸ ğŸ° ğŸ¢ ğŸ­ ğŸ—¼ ğŸ—½ ğŸ—¿"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-17.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-17:m128"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
